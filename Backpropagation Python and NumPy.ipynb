{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f222aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:01:24.366833Z",
     "start_time": "2021-07-29T16:01:24.364315Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7405f7a3",
   "metadata": {},
   "source": [
    "Based on https://techcommunity.microsoft.com/t5/educator-developer-blog/how-to-implement-the-backpropagation-using-python-and-numpy/ba-p/378895\n",
    "# How to implement the backpropagation using Python and NumPy\n",
    "By Lee Stott\n",
    "## First published on MSDN on Jul 04, 2017\n",
    "I was recently speaking to a University Academic and we got into the discussion of practical assessments for Data Science Students, One of the key principles students learn is how to implement the back-propagation neural network training algorithm. Many students start by learning this method from scratch, using just Python 3.x and the NumPy package.\n",
    "\n",
    "The following is a Guest post by Dr. James McCaffrey Microsoft Research this article was originally published at Visual Studio Magazine the article has been increased to include some additional resources and interactive demos using the Azure Notebooks Service.\n",
    "\n",
    "After reading this you should have a solid grasp of back-propagation, as well as knowledge of Python and NumPy techniques that will be useful when working with libraries such as CNTK and TensorFlow. .\n",
    "\n",
    "## Example using the Iris Dataset\n",
    "The [Iris Data Set](https://en.wikipedia.org/wiki/Iris_flower_data_set) has over 150 item records. Each item has four numeric predictor variables (often called features): sepal length and width, and petal length and width, followed by the species (\"setosa,\" \"versicolor\" or \"virginica\").\n",
    "\n",
    "The demo program uses 1-of-N label encoding\n",
    "\n",
    "- setosa = (1,0,0)\n",
    "- versicolor = (0,1,0)\n",
    "- virginica = (0,0,1)\n",
    "The goal is to predict species from sepal and petal length and width.  The 150-item dataset has 50 setosa items, followed by 50 versicolor, followed by 50 virginica. Before writing the demo program,\n",
    "\n",
    "There is a 120-item file of training data (using the first 30 of each species) and a 30-item file of test data (the leftover 10 of each species). https://github.com/leestott/IrisData/blob/master/irisTrainData.txt\n",
    "\n",
    "The demo program creates a simple neural network with four input nodes (one for each feature), five hidden processing nodes (the number of hidden nodes is a free parameter and must be determined by trial and error), and three output nodes (corresponding to encoded species). The demo loaded the training and test data into two matrices.\n",
    "\n",
    "The back-propagation algorithm is iterative and you must supply a maximum number of iterations (50 in the demo) and a learning rate (0.050) that controls how much each weight and bias value changes in each iteration. Small learning rate values lead to slow but steady training. Large learning rates lead to quicker training at the risk of overshooting good weight and bias values. The max-iteration and leaning rate are free parameters.\n",
    "\n",
    "The demo displays the value of the mean squared error, every 10 iterations during training. As you'll see shortly, there are two error types that are commonly used with back-propagation, and the choice of error type affects the back-propagation implementation. After training completed, the demo computed the classification accuracy of the resulting model on the training data (0.9333 = 112 out of 120 correct) and on the test data (0.9667 = 29 out of 30 correct). The classification accuracy on a set of test data is a very rough approximation of the accuracy you'd expect to see on new, previously unseen data.\n",
    "\n",
    "The demo program is too long to present in its entirety in this article, but the complete source code is available in the accompanying file download. https://github.com/leestott/IrisData\n",
    "\n",
    "## Understanding Back-Propagation\n",
    "\n",
    "Back-propagation is arguably the single most important algorithm in machine learning. A complete understanding of back-propagation takes a lot of effort. But from a developer's perspective, there are only a few key concepts that are needed to implement back-propagation. In the discussion that follows, for simplicity I leave out many important details, and take many liberties with the underlying mathematics.\n",
    "\n",
    "Take a look at the two math equations for back-propagation. The top equation defines a sum of squares error metric and is the starting point for back-propagation. The tj stands for a target value and the oj stands for a computed output value. Suppose a target value is (1, 0, 0) corresponding to setosa. And suppose that for a given set of weight and bias values, and a set of four input values, the computed output values are (0.70, 0.10, 0.20). The squared error is 1/2 * [ (1 - 0.70)^2 + (0 - 0.10)^2 + (0 - 0.20)^2 ] = 1/2 * (0.09 + 0.01 + 0.04) = 0.07. Notice the seemingly arbitrary 1/2 term.\n",
    "\n",
    "\n",
    "## Back-Propagation Update for Hidden-to-Output Weights\n",
    "The goal of back-propagation training is to minimize the squared error. To do that, the gradient of the error function must be calculated. The gradient is a calculus derivative with a value like +1.23 or -0.33. The sign of the gradient tells you whether to increase or decrease the weights and biases in order to reduce error. The magnitude of the gradient is used, along with the learning rate, to determine how much to increase or decrease the weights and biases.\n",
    "\n",
    "Using some very clever mathematics, you can compute the gradient. The bottom equation is the weight update rule for a single output node. The amount to change a particular weight is the learning rate (alpha) times the gradient. The gradient has four terms. The xi is the input associated with the weight thatâ€™s being examined. The (oj - tj) is the derivative of the outside part of the error function: the 2 exponent drops to the front, cancelling the 1/2 (which is the only reason the 1/2 term is there), then you multiply by the derivative of the inside, which is -1 times the derivative of the function used to compute the output node.\n",
    "\n",
    "The third and fourth terms of the gradient come from the activation function used for the output nodes. For classification, this is the softmax function. As it turns out, the derivative of an output node oj is, somewhat surprisingly, oj * (1 - oj). To summarize, the back-propagation weight update rule depends on the derivative of the error function and the derivative of the activation function.\n",
    "\n",
    "There are some important additional details. The squared error term can be defined using (target -output)^2 instead of (output - target)^2 and give the same error because of the squaring operation. But reversing the order will change the sign of the resulting (target - output) term in the gradient. This in turn affects whether you should add the delta-w term or subtract it when you update weights and biases.\n",
    "\n",
    "OK, so updating the weights and biases for hidden-to-output weights isn't too difficult. But what about the weight update rule for input-to-hidden weights? That equation is more complicated and in my opinion is best understood using code rather than a math equation, as I'll present shortly. The Wikipedia article on back-propagation has a very good derivation of the weight update rule for both output and hidden nodes.\n",
    "# Overall Demo Program Structure\n",
    "\n",
    "The overall demo program structure is presented in Listing 1 .\n",
    "\n",
    "To edit the demo program, I commented the name of the program and indicated the Python version used. I added four import statements to gain access to the NumPy package's array and matrix data structures, and the math and random modules. The sys module is used only to programmatically display the Python version, and can be omitted in most scenarios.\n",
    "\n",
    "Listing 1: Overall Program Structure https://github.com/leestott/IrisData/blob/master/nn_backprop.py\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "Implementing a neural network in Python gives you a complete understanding of what goes on behind the scenes when you use a sophisticated machine learning library like CNTK or TensorFlow, the ability to implement a neural network from scratch gives you the ability to experiment with custom algorithms. The version of back-propagation presented in this article is basic example to help students get started with Python and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61798e0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:50:31.818793Z",
     "start_time": "2021-07-29T16:50:31.725091Z"
    }
   },
   "outputs": [],
   "source": [
    "# nn_backprop.py\n",
    "# Python 3.x\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42c9504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:50:31.831303Z",
     "start_time": "2021-07-29T16:50:31.822553Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# helper functions\n",
    "\n",
    "def loadFile(df):\n",
    "  # load a comma-delimited text file into an np matrix\n",
    "  resultList = []\n",
    "  f = open(df, 'r')\n",
    "  for line in f:\n",
    "    line = line.rstrip('\\n')  # \"1.0,2.0,3.0\"\n",
    "    sVals = line.split(',')   # [\"1.0\", \"2.0, \"3.0\"]\n",
    "    fVals = list(map(np.float32, sVals))  # [1.0, 2.0, 3.0]\n",
    "    resultList.append(fVals)  # [[1.0, 2.0, 3.0] , [4.0, 5.0, 6.0]]\n",
    "  f.close()\n",
    "  return np.asarray(resultList, dtype=np.float32)  # not necessary\n",
    "# end loadFile\n",
    "  \n",
    "def showVector(v, dec):\n",
    "  fmt = \"%.\" + str(dec) + \"f\" # like %.4f\n",
    "  for i in range(len(v)):\n",
    "    x = v[i]\n",
    "    if x >= 0.0: print(' ', end='')\n",
    "    print(fmt % x + '  ', end='')\n",
    "  print('')\n",
    "  \n",
    "def showMatrix(m, dec):\n",
    "  fmt = \"%.\" + str(dec) + \"f\" # like %.4f  \n",
    "  for i in range(len(m)):\n",
    "    for j in range(len(m[i])):\n",
    "      x = m[i,j]\n",
    "      if x >= 0.0: print(' ', end='')\n",
    "      print(fmt % x + '  ', end='')\n",
    "    print('')\n",
    "\n",
    "def showMatrixPartial(m, numRows, dec, indices):\n",
    "  fmt = \"%.\" + str(dec) + \"f\" # like %.4f\n",
    "  lastRow = len(m) - 1\n",
    "  width = len(str(lastRow))\n",
    "  for i in range(numRows):\n",
    "    if indices == True:\n",
    "      print(\"[\", end='')\n",
    "      print(str(i).rjust(width), end='')\n",
    "      print(\"] \", end='')\t  \n",
    "  \n",
    "    for j in range(len(m[i])):\n",
    "      x = m[i,j]\n",
    "      if x >= 0.0: print(' ', end='')\n",
    "      print(fmt % x + '  ', end='')\n",
    "    print('')\n",
    "  print(\" . . . \")\n",
    "\n",
    "  if indices == True:\n",
    "    print(\"[\", end='')\n",
    "    print(str(lastRow).rjust(width), end='')\n",
    "    print(\"] \", end='')\t  \n",
    "  for j in range(len(m[lastRow])):\n",
    "    x = m[lastRow,j]\n",
    "    if x >= 0.0: print(' ', end='')\n",
    "    print(fmt % x + '  ', end='')\n",
    "  print('')\t  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafbaa6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:50:31.836930Z",
     "start_time": "2021-07-29T16:50:31.832595Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a NeuralNetwork class that contains the number of input, hidden, and output nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09636c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:50:31.862834Z",
     "start_time": "2021-07-29T16:50:31.838245Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, numInput, numHidden, numOutput, seed):\n",
    "        self.ni = numInput\n",
    "        self.nh = numHidden\n",
    "        self.no = numOutput\n",
    "\n",
    "        self.iNodes = np.zeros(shape=[self.ni], dtype=np.float32)\n",
    "        self.hNodes = np.zeros(shape=[self.nh], dtype=np.float32)\n",
    "        self.oNodes = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "\n",
    "        self.ihWeights = np.zeros(shape=[self.ni, self.nh], dtype=np.float32)\n",
    "        self.hoWeights = np.zeros(shape=[self.nh, self.no], dtype=np.float32)\n",
    "\n",
    "        self.hBiases = np.zeros(shape=[self.nh], dtype=np.float32)\n",
    "        self.oBiases = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "\n",
    "        self.rnd = random.Random(seed)  # allows multiple instances\n",
    "        self.initializeWeights()\n",
    "\n",
    "    def setWeights(self, weights):\n",
    "        if len(weights) != self.totalWeights(self.ni, self.nh, self.no):\n",
    "            print(\"Warning: len(weights) error in setWeights()\")\n",
    "\n",
    "        idx = 0\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                self.ihWeights[i, j] = weights[idx]\n",
    "                idx += 1\n",
    "\n",
    "        for j in range(self.nh):\n",
    "            self.hBiases[j] = weights[idx]\n",
    "            idx += 1\n",
    "\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                self.hoWeights[j, k] = weights[idx]\n",
    "                idx += 1\n",
    "\n",
    "        for k in range(self.no):\n",
    "            self.oBiases[k] = weights[idx]\n",
    "            idx += 1\n",
    "\n",
    "    def getWeights(self):\n",
    "        tw = self.totalWeights(self.ni, self.nh, self.no)\n",
    "        result = np.zeros(shape=[tw], dtype=np.float32)\n",
    "        idx = 0  # points into result\n",
    "\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                result[idx] = self.ihWeights[i, j]\n",
    "                idx += 1\n",
    "\n",
    "        for j in range(self.nh):\n",
    "            result[idx] = self.hBiases[j]\n",
    "            idx += 1\n",
    "\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                result[idx] = self.hoWeights[j, k]\n",
    "                idx += 1\n",
    "\n",
    "        for k in range(self.no):\n",
    "            result[idx] = self.oBiases[k]\n",
    "            idx += 1\n",
    "\n",
    "        return result\n",
    "\n",
    "    def initializeWeights(self):\n",
    "        numWts = self.totalWeights(self.ni, self.nh, self.no)\n",
    "        wts = np.zeros(shape=[numWts], dtype=np.float32)\n",
    "        lo = -0.01\n",
    "        hi = 0.01\n",
    "        for idx in range(len(wts)):\n",
    "            wts[idx] = (hi - lo) * self.rnd.random() + lo\n",
    "        self.setWeights(wts)\n",
    "\n",
    "    def computeOutputs(self, xValues):\n",
    "        hSums = np.zeros(shape=[self.nh], dtype=np.float32)\n",
    "        oSums = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "\n",
    "        for i in range(self.ni):\n",
    "            self.iNodes[i] = xValues[i]\n",
    "\n",
    "        for j in range(self.nh):\n",
    "            for i in range(self.ni):\n",
    "                hSums[j] += self.iNodes[i] * self.ihWeights[i, j]\n",
    "\n",
    "        for j in range(self.nh):\n",
    "            hSums[j] += self.hBiases[j]\n",
    "\n",
    "        for j in range(self.nh):\n",
    "            self.hNodes[j] = self.hypertan(hSums[j])\n",
    "\n",
    "        for k in range(self.no):\n",
    "            for j in range(self.nh):\n",
    "                oSums[k] += self.hNodes[j] * self.hoWeights[j, k]\n",
    "\n",
    "        for k in range(self.no):\n",
    "            oSums[k] += self.oBiases[k]\n",
    "\n",
    "        softOut = self.softmax(oSums)\n",
    "        for k in range(self.no):\n",
    "            self.oNodes[k] = softOut[k]\n",
    "\n",
    "        result = np.zeros(shape=self.no, dtype=np.float32)\n",
    "        for k in range(self.no):\n",
    "            result[k] = self.oNodes[k]\n",
    "\n",
    "        return result\n",
    "\n",
    "    def train(self, trainData, maxEpochs, learnRate,provideUpdates = True):\n",
    "        hoGrads = np.zeros(\n",
    "            shape=[self.nh, self.no],\n",
    "            dtype=np.float32)  # hidden-to-output weights gradients\n",
    "        obGrads = np.zeros(shape=[self.no],\n",
    "                           dtype=np.float32)  # output node biases gradients\n",
    "        ihGrads = np.zeros(\n",
    "            shape=[self.ni, self.nh],\n",
    "            dtype=np.float32)  # input-to-hidden weights gradients\n",
    "        hbGrads = np.zeros(shape=[self.nh],\n",
    "                           dtype=np.float32)  # hidden biases gradients\n",
    "\n",
    "        oSignals = np.zeros(\n",
    "            shape=[self.no], dtype=np.float32\n",
    "        )  # output signals: gradients w/o assoc. input terms\n",
    "        hSignals = np.zeros(\n",
    "            shape=[self.nh], dtype=np.float32\n",
    "        )  # hidden signals: gradients w/o assoc. input terms\n",
    "\n",
    "        epoch = 0\n",
    "        x_values = np.zeros(shape=[self.ni], dtype=np.float32)\n",
    "        t_values = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "        numTrainItems = len(trainData)\n",
    "        indices = np.arange(\n",
    "            numTrainItems)  # [0, 1, 2, . . n-1]  # rnd.shuffle(v)\n",
    "\n",
    "        while epoch < maxEpochs:\n",
    "            self.rnd.shuffle(indices)  # scramble order of training items\n",
    "            for ii in range(numTrainItems):\n",
    "                idx = indices[ii]\n",
    "\n",
    "                for j in range(self.ni):\n",
    "                    x_values[j] = trainData[idx, j]  # get the input values\n",
    "                for j in range(self.no):\n",
    "                    t_values[j] = trainData[idx, j +\n",
    "                                            self.ni]  # get the target values\n",
    "                self.computeOutputs(x_values)  # results stored internally\n",
    "\n",
    "                # 1. compute output node signals\n",
    "                for k in range(self.no):\n",
    "                    derivative = (1 -\n",
    "                                  self.oNodes[k]) * self.oNodes[k]  # softmax\n",
    "                    oSignals[k] = derivative * (self.oNodes[k] - t_values[k]\n",
    "                                                )  # E=(t-o)^2 do E'=(o-t)\n",
    "\n",
    "                # 2. compute hidden-to-output weight gradients using output signals\n",
    "                for j in range(self.nh):\n",
    "                    for k in range(self.no):\n",
    "                        hoGrads[j, k] = oSignals[k] * self.hNodes[j]\n",
    "\n",
    "                # 3. compute output node bias gradients using output signals\n",
    "                for k in range(self.no):\n",
    "                    obGrads[k] = oSignals[\n",
    "                        k] * 1.0  # 1.0 dummy input can be dropped\n",
    "\n",
    "                # 4. compute hidden node signals\n",
    "                for j in range(self.nh):\n",
    "                    sum = 0.0\n",
    "                    for k in range(self.no):\n",
    "                        sum += oSignals[k] * self.hoWeights[j, k]\n",
    "                    derivative = (1 - self.hNodes[j]) * (1 + self.hNodes[j]\n",
    "                                                         )  # tanh activation\n",
    "                    hSignals[j] = derivative * sum\n",
    "\n",
    "                # 5 compute input-to-hidden weight gradients using hidden signals\n",
    "                for i in range(self.ni):\n",
    "                    for j in range(self.nh):\n",
    "                        ihGrads[i, j] = hSignals[j] * self.iNodes[i]\n",
    "\n",
    "                # 6. compute hidden node bias gradients using hidden signals\n",
    "                for j in range(self.nh):\n",
    "                    hbGrads[j] = hSignals[\n",
    "                        j] * 1.0  # 1.0 dummy input can be dropped\n",
    "\n",
    "                # update weights and biases using the gradients\n",
    "\n",
    "                # 1. update input-to-hidden weights\n",
    "                for i in range(self.ni):\n",
    "                    for j in range(self.nh):\n",
    "                        delta = -1.0 * learnRate * ihGrads[i, j]\n",
    "                        self.ihWeights[i, j] += delta\n",
    "\n",
    "                # 2. update hidden node biases\n",
    "                for j in range(self.nh):\n",
    "                    delta = -1.0 * learnRate * hbGrads[j]\n",
    "                    self.hBiases[j] += delta\n",
    "\n",
    "                # 3. update hidden-to-output weights\n",
    "                for j in range(self.nh):\n",
    "                    for k in range(self.no):\n",
    "                        delta = -1.0 * learnRate * hoGrads[j, k]\n",
    "                        self.hoWeights[j, k] += delta\n",
    "\n",
    "                # 4. update output node biases\n",
    "                for k in range(self.no):\n",
    "                    delta = -1.0 * learnRate * obGrads[k]\n",
    "                    self.oBiases[k] += delta\n",
    "\n",
    "            epoch += 1\n",
    "\n",
    "            if provideUpdates and epoch % 10 == 0:\n",
    "                mse = self.meanSquaredError(trainData)\n",
    "                print(\"epoch = \" + str(epoch) + \" error = %0.4f \" % mse)\n",
    "        # end while\n",
    "\n",
    "        result = self.getWeights()\n",
    "        return result\n",
    "\n",
    "    # end train\n",
    "\n",
    "    def accuracy(self, tdata):  # train or test data matrix\n",
    "        num_correct = 0\n",
    "        num_wrong = 0\n",
    "        x_values = np.zeros(shape=[self.ni], dtype=np.float32)\n",
    "        t_values = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "\n",
    "        for i in range(len(tdata)):  # walk thru each data item\n",
    "            for j in range(\n",
    "                    self.ni):  # peel off input values from curr data row\n",
    "                x_values[j] = tdata[i, j]\n",
    "            for j in range(\n",
    "                    self.no):  # peel off tareget values from curr data row\n",
    "                t_values[j] = tdata[i, j + self.ni]\n",
    "\n",
    "            y_values = self.computeOutputs(x_values)  # computed output values)\n",
    "            max_index = np.argmax(y_values)  # index of largest output value\n",
    "\n",
    "            if abs(t_values[max_index] - 1.0) < 1.0e-5:\n",
    "                num_correct += 1\n",
    "            else:\n",
    "                num_wrong += 1\n",
    "\n",
    "        return (num_correct * 1.0) / (num_correct + num_wrong)\n",
    "\n",
    "    def meanSquaredError(self, tdata):  # on train or test data matrix\n",
    "        sumSquaredError = 0.0\n",
    "        x_values = np.zeros(shape=[self.ni], dtype=np.float32)\n",
    "        t_values = np.zeros(shape=[self.no], dtype=np.float32)\n",
    "\n",
    "        for ii in range(len(tdata)):  # walk thru each data item\n",
    "            for jj in range(\n",
    "                    self.ni):  # peel off input values from curr data row\n",
    "                x_values[jj] = tdata[ii, jj]\n",
    "            for jj in range(\n",
    "                    self.no):  # peel off tareget values from curr data row\n",
    "                t_values[jj] = tdata[ii, jj + self.ni]\n",
    "\n",
    "            y_values = self.computeOutputs(x_values)  # computed output values\n",
    "\n",
    "            for j in range(self.no):\n",
    "                err = t_values[j] - y_values[j]\n",
    "                sumSquaredError += err * err  # (t-o)^2\n",
    "\n",
    "        return sumSquaredError / len(tdata)\n",
    "\n",
    "    @staticmethod\n",
    "    def hypertan(x):\n",
    "        if x < -20.0:\n",
    "            return -1.0\n",
    "        elif x > 20.0:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return math.tanh(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(oSums):\n",
    "        result = np.zeros(shape=[len(oSums)], dtype=np.float32)\n",
    "        m = max(oSums)\n",
    "        divisor = 0.0\n",
    "        for k in range(len(oSums)):\n",
    "            divisor += math.exp(oSums[k] - m)\n",
    "        for k in range(len(result)):\n",
    "            result[k] = math.exp(oSums[k] - m) / divisor\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def totalWeights(nInput, nHidden, nOutput):\n",
    "        tw = (nInput * nHidden) + (nHidden * nOutput) + nHidden + nOutput\n",
    "        return tw\n",
    "\n",
    "\n",
    "# end class NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949bc6a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T15:54:16.086352Z",
     "start_time": "2021-07-29T15:54:16.075281Z"
    }
   },
   "source": [
    "# Begin NN back-propagation demo\n",
    "The demo program consists mostly of a program-defined NeuralNetwork class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc341ddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:50:31.869403Z",
     "start_time": "2021-07-29T16:50:31.864082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python version 3.9.5 | packaged by conda-forge | (default, Jun 19 2021, 00:32:32) \n",
      "[GCC 9.3.0]\n",
      " and NumPy version 1.19.5\n"
     ]
    }
   ],
   "source": [
    "pv = sys.version\n",
    "npv = np.version.version\n",
    "print(\"Using Python version \" + str(pv) + \"\\n and NumPy version \" + str(npv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5334bdf",
   "metadata": {},
   "source": [
    "## Create a demo neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82818baf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:50:31.874011Z",
     "start_time": "2021-07-29T16:50:31.871087Z"
    }
   },
   "outputs": [],
   "source": [
    "numInput = 4\n",
    "numHidden = 5\n",
    "numOutput = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ea9a7fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:50:31.880529Z",
     "start_time": "2021-07-29T16:50:31.875755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating a 4-5-3 neural network \n",
      "\n",
      "Created a 4-5-3 neural network \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nCreating a %d-%d-%d neural network \" %\n",
    "      (numInput, numHidden, numOutput))\n",
    "nn = NeuralNetwork(numInput, numHidden, numOutput, seed=3)\n",
    "print(\"\\nCreated a %d-%d-%d neural network \" %\n",
    "      (numInput, numHidden, numOutput))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72d43865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:50:32.901221Z",
     "start_time": "2021-07-29T16:50:31.883266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Iris training and test data \n",
      "\n",
      "Test data: \n",
      "[  0]  4.9   3.0   1.4   0.2   1.0   0.0   0.0  \n",
      "[  1]  4.7   3.2   1.3   0.2   1.0   0.0   0.0  \n",
      "[  2]  4.6   3.1   1.5   0.2   1.0   0.0   0.0  \n",
      "[  3]  5.0   3.6   1.4   0.2   1.0   0.0   0.0  \n",
      " . . . \n",
      "[118]  6.9   3.1   5.4   2.1   0.0   0.0   1.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading Iris training and test data \")\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"https://raw.githubusercontent.com/leestott/IrisData/master/irisTrainData.txt\",header=0)\n",
    "test_df = pd.read_csv(\"https://raw.githubusercontent.com/leestott/IrisData/master/irisTestData.txt\",header =0)\n",
    "trainDataMatrix = train_df.to_numpy()\n",
    "print(\"\\nTest data: \")\n",
    "\n",
    "showMatrixPartial(trainDataMatrix, 4, 1, True)\n",
    "\n",
    "testDataMatrix = test_df.to_numpy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90965774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:50:32.906099Z",
     "start_time": "2021-07-29T16:50:32.902773Z"
    }
   },
   "outputs": [],
   "source": [
    "maxEpochs = 50\n",
    "learnRate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23de36e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:50:34.505268Z",
     "start_time": "2021-07-29T16:50:32.907532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting maxEpochs = 50\n",
      "Setting learning rate = 0.050 \n",
      "\n",
      "Starting training\n",
      "epoch = 10 error = 0.2987 \n",
      "epoch = 20 error = 0.1116 \n",
      "epoch = 30 error = 0.0710 \n",
      "epoch = 40 error = 0.0670 \n",
      "epoch = 50 error = 0.0591 \n",
      "Training complete\n",
      "\n",
      "Accuracy on 120-item train data = 0.9664 \n",
      "Accuracy on 30-item test data   = 1.0000 \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSetting maxEpochs = \" + str(maxEpochs))\n",
    "print(\"Setting learning rate = %0.3f \" % learnRate)\n",
    "print(\"\\nStarting training\")\n",
    "nn.train(trainDataMatrix, maxEpochs, learnRate)\n",
    "print(\"Training complete\")\n",
    "\n",
    "accTrain = nn.accuracy(trainDataMatrix)\n",
    "accTest = nn.accuracy(testDataMatrix)\n",
    "\n",
    "print(\"\\nAccuracy on 120-item train data = %0.4f \" % accTrain)\n",
    "print(\"Accuracy on 30-item test data   = %0.4f \" % accTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c2db02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:42:27.767418Z",
     "start_time": "2021-07-29T16:42:27.764753Z"
    }
   },
   "source": [
    "# Demonstration of Over Fitting\n",
    "If a little does a little good then..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1187d496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:50:34.510506Z",
     "start_time": "2021-07-29T16:50:34.506874Z"
    }
   },
   "outputs": [],
   "source": [
    "def TrainTest(maxEpochs=50,learnRate = 0.05):\n",
    "    nn = NeuralNetwork(numInput, numHidden, numOutput, seed=3)\n",
    "    nn.train(trainDataMatrix, maxEpochs, learnRate,False)\n",
    "    return maxEpochs, nn.accuracy(trainDataMatrix),nn.accuracy(testDataMatrix),nn.meanSquaredError(trainDataMatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be54a885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:50:36.138244Z",
     "start_time": "2021-07-29T16:50:34.512037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.33613445378151263, 0.3448275862068966, 0.6656051271853327)\n",
      "(50, 0.9663865546218487, 1.0, 0.0590952597919678)\n"
     ]
    }
   ],
   "source": [
    "# just to make sure we're getting valid results\n",
    "print(TrainTest(1))\n",
    "print(TrainTest(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953214c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:38:01.932904Z",
     "start_time": "2021-07-29T16:38:01.755051Z"
    }
   },
   "source": [
    "### Means Squared Error\n",
    "Recall MSE is the sum of the differences squared between estimated and actual values.  We want to minimize it, to a point. After a certain point, the MSE may continue to decrease but the accuracy of the model may also decrease.  This is called over fitting.  Using other words, the model may do very well on some of the data it has seen, but very poorly on things it has not seen.\n",
    "\n",
    "\\begin{equation}\n",
    "\\textrm{MSE}(y, \\hat{y} ) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^{2}\n",
    "\\end{equation}\n",
    "\n",
    "R2  is a normalized version of MSE\n",
    "\n",
    "\\begin{equation}\n",
    "\\textrm{R}^2(y, \\hat{y} ) = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y_i})^{2}}{ \\sum_{i=1}^{n} (y_i - \\bar{y})^{2} }\n",
    "\\end{equation}\n",
    "\n",
    "R2 is useful because it is often easier to interpret since it doesn't depend on the scale of the data.\n",
    "\n",
    "https://stats.stackexchange.com/questions/250730/what-is-the-mathematical-relationship-between-r2-and-mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fecf716b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:54:06.470936Z",
     "start_time": "2021-07-29T16:53:35.956996Z"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(1,100,5):\n",
    "    results.append(TrainTest(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36eb3bab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:54:06.476742Z",
     "start_time": "2021-07-29T16:54:06.473287Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_records(results, columns =['epoch', 'train_accuracy', 'test_accuracy','epoch_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66c1d405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:54:06.486213Z",
     "start_time": "2021-07-29T16:54:06.478584Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = results_df.set_index(\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53a17616",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:54:06.498684Z",
     "start_time": "2021-07-29T16:54:06.488555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>epoch_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.336134</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.665605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.663866</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.337058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.249515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.840336</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.208812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.949580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.113406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.422040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.974790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.159932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.111335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.949580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.957983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.075334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.957983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.957983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.108320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.109798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.966387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.086080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.974790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.078261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_accuracy  test_accuracy  epoch_error\n",
       "epoch                                            \n",
       "1            0.336134       0.344828     0.665605\n",
       "6            0.663866       0.689655     0.337058\n",
       "11           0.831933       0.896552     0.249515\n",
       "16           0.840336       0.896552     0.208812\n",
       "21           0.949580       1.000000     0.113406\n",
       "26           0.689076       0.655172     0.422040\n",
       "31           0.974790       1.000000     0.072599\n",
       "36           0.882353       0.931034     0.159932\n",
       "41           0.924370       0.965517     0.111335\n",
       "46           0.949580       1.000000     0.064367\n",
       "51           0.957983       1.000000     0.073019\n",
       "56           0.924370       0.965517     0.075334\n",
       "61           0.957983       1.000000     0.057799\n",
       "66           0.957983       1.000000     0.067978\n",
       "71           0.915966       0.965517     0.108320\n",
       "76           0.924370       0.965517     0.109798\n",
       "81           0.966387       1.000000     0.052306\n",
       "86           0.924370       0.965517     0.086080\n",
       "91           0.974790       1.000000     0.047908\n",
       "96           0.924370       0.965517     0.078261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e268a7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T16:54:06.655755Z",
     "start_time": "2021-07-29T16:54:06.499955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='epoch'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecd34a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
